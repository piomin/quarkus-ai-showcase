# Select AI provider: openai, mistral, or ollama
ai.model.provider=${AI_MODEL_PROVIDER:openai}

quarkus.langchain4j.chat-model.provider = openai

# OpenAI Configuration
quarkus.langchain4j.openai.api-key = ${OPENAI_API_KEY}
quarkus.langchain4j.openai.timeout = 20s
quarkus.langchain4j.openai.log-requests = true
quarkus.langchain4j.openai.log-responses = false

# Mistral AI Configuration
quarkus.langchain4j.mistralai.api-key = ${MISTRAL_API_KEY}
quarkus.langchain4j.mistralai.timeout = 20s
quarkus.langchain4j.mistralai.log-requests = true
quarkus.langchain4j.mistralai.log-responses = false

# Ollama Configuration
quarkus.langchain4j.ollama.base-url = ${OLLAMA_BASE_URL:http://localhost:11434}
quarkus.langchain4j.ollama.log-requests = true
quarkus.langchain4j.ollama.log-responses = false

# Development profile overrides
%dev.quarkus.log.console.enable = true
%dev.quarkus.log.console.level = DEBUG